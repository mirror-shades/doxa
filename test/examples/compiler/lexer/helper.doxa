import TokenType from "./token.doxa"

const alpha is [
    ..."a", "b", "c", "d", "e", "f", "g", "h", "i", 
    ..."j", "k", "l", "m", "n", "o", "p", "q", "r", 
    ..."s", "t", "u", "v", "w", "x", "y", "z", 
    ..."A", "B", "C", "D", "E", "F", "G", "H", "I", 
    ..."J", "K", "L", "M", "N", "O", "P", "Q", "R", 
    ..."S", "T", "U", "V", "W", "X", "Y", "Z"]

const numeric is ["1", "2", "3", "4", "5", "6", "7", "8", "9", "0"]

const keywords is ["var", "const", "function", "entry", "is"]

// ERROR here, returns token type not found in declared tokens I think
pub const map LiteralToToken :: string returns TokenType {
    "var" then TokenType.VAR,
    "const" then TokenType.CONST,
    "function" then TokenType.FUNCTION,
    "entry" then TokenType.ENTRY,
    "is" then TokenType.ASSIGN
}

pub function isAlpha(char :: string) returns tetra {
    if @length(char) > 1 then @print("isAlpha received a string longer than one: {char}\n")
    if @length(char) == 0 then @print("isAlpha received an empty string")

    return exists e in alpha where char == e
}

pub function isNumeric(char :: string) returns tetra {
    if @length(char) > 1 then @print("isNumeric received a string longer than one: {char}\n")
    if @length(char) == 0 then @print("isNumeric received an empty string")

    return exists e in numeric where char == e
}

pub function isKeyword(word :: string) returns tetra {
    if @length(word) == 0 then @print("isKeyword received an empty string")

    return exists e in keywords where word == e
}