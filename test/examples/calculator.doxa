enum TokenType {
    NUMBER,
    OPERATOR,
    LPAREN,
    RPAREN,
}

struct Token {
    token_type :: TokenType,
    value :: string,
}

fn precedence(op :: string) -> int {
    return match op {
        "(" then 0,
        ")" then 0,
        "+" then 1,
        "-" then 1,
        "*" then 2,
        "/" then 2,
        else -1,
    }
}

entry fn main() {
    // all compiler level methods are distinguished by @
    const input is @input()

    const splitInput is split(input)

    splitInput?

    @assert(verifyParens(splitInput))

    const possibleTokens is tokenize(splitInput)

    // union needs to be narrowed to catch our error returns
    possibleTokens as Token[] then {
        execute(possibleTokens)
    } else {
        "tokens failed to parse"?
        return
    }

    return
}

fn split(input :: string) -> string[] {
    var result :: string[]
    var current is ""

    const lin is @length(input)

    // `each` loops iterate through each element
    // they can work on strings as well as arrays
    // `at` is optional syntax for a loop index
    each c at i in input {
        // breaks number if operator is found
        if c equals " " then {
            if current != "" then {
                @push(result, current)
                current is ""
            }
        }

        else if c equals "+" or c equals "*" or c equals "/" or c equals "(" or c equals ")" then {
            if current != "" then {
                @push(result, current)
                current is ""
            }
            @push(result, c)
        }

        // make sure - isn't a negative sign
        else if c equals "-" and input[i+1] equals " " then {
            if current != "" then {
                @push(result, current)
                current is ""
            }
            @push(result, c)
        } 

        else if c != " " {
            current is current + c
        }

    }
    @push(result, current)
    return result
}

fn verifyParens(input :: string[]) -> tetra {
    var depth is 0
    var passed :: tetra is true
    each s in input {
        if s equals "(" then depth += 1
        if s equals ")" then depth -= 1
        if depth < 0 then {
            passed is false
        }
    }
    if depth > 0 then {
        passed is false
    }
    return passed
}

fn tokenize(input :: string[]) -> Token[] | nothing {
    var tokens :: Token[]

    each token in input {
        if token equals "+" or token equals "-" or token equals "*" or token equals "/" then {
            @push(tokens, Token {
                token_type is .OPERATOR,
                value is token,
            })
        } 
        else if token equals "(" then {
            @push(tokens, Token {
                token_type is .LPAREN,
                value is token,
            })
        } 
        else if token equals ")" then {
            @push(tokens, Token {
                token_type is .RPAREN,
                value is token,
            })
        } else {
            @push(tokens, Token { 
                token_type is .NUMBER,
                value is token,
            })
    }
    }
    return tokens
}

fn execute(tokens :: Token[]) {
	var total :: int is 0
	const first is @int(tokens[0].value)
	first as int then {
		total is first
	} else {
		tokens[0].token_type?;
		tokens[0].value?;
		"first value must be a number"?;
		return
	}
	each token at i in tokens {
		if i != 0 then {
			token.token_type?;
			if token.token_type equals TokenType.OPERATOR then {
				// narrow operator value to string and process in success branch
				const op is token.value

				const next is tokens[i + 1]
				const rightHand is @int(next.value) as int else {
					next.value?;
					"value must be a number"?;
					return
				}

				if op equals "+" then { total += rightHand }
				else if op equals "-" then { total -= rightHand }
				else if op equals "*" then { total *= rightHand }
				else if op equals "/" then { total /= rightHand }
				else { op?; "invalid operator"?; return }
			}
		}
	}
	total?
	return
}